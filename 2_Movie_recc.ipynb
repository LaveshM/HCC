{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "387968da",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------\n",
    "# CS616-Assignment 2\n",
    "\n",
    "-------------------------------------------------------------------------------------------\n",
    "The goal of this assignment is to implement the various recommender system algorithms learnt in class. I implemented and evaluated recommender systems based on the following algorithms:\n",
    "1. Matrix Factorisation Based \n",
    "2. Content-based Collaborative Filtering\n",
    "3. Profile-based Collaborative Filtering\n",
    "4. Hybrid (Mixture of Content and Profile based) \n",
    "\n",
    "The algorithms are implemented on the MovieLens dataset, which had the following information:\n",
    "- Information about movies: 1682 movies cateogarised into 20 genres\n",
    "- Information about users: The dataset contains information of IMDB users, such as their sex, age, postal code and their ratings for the above 1682 movies. \n",
    "\n",
    "The dataset was already split into multiple training and test sets. The first set (u1.base) was used to feed information into the algorithms, and u1.test to tune the hyperparameters related to each algorithm. The final results are shown on the u2.base and u2.test datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b60e5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import pairwise\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import scipy.stats as stats\n",
    "from geopy.geocoders import Nominatim\n",
    "from scipy.spatial.distance import pdist, squareform"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a0cbadd7",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4645a30a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  age sex  occupation    zip\n",
      "0   1   24   M  technician  85711\n",
      "1   2   53   F       other  94043\n",
      "2   3   23   M      writer  32067\n",
      "3   4   24   M  technician  43537\n",
      "4   5   33   F       other  15213\n"
     ]
    }
   ],
   "source": [
    "userProfiles=pd.read_csv(\"./ml-100k/u.user\",sep=\"|\",header=None)\n",
    "userProfiles=userProfiles.rename(columns={0:\"id\",1:\"age\",2:\"sex\",3:\"occupation\",4:\"zip\"})\n",
    "print(userProfiles.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "834725f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  id              title      release  \\\n",
      "0  1   Toy Story (1995)  01-Jan-1995   \n",
      "1  2   GoldenEye (1995)  01-Jan-1995   \n",
      "2  3  Four Rooms (1995)  01-Jan-1995   \n",
      "3  4  Get Shorty (1995)  01-Jan-1995   \n",
      "4  5     Copycat (1995)  01-Jan-1995   \n",
      "\n",
      "                                               genre  \n",
      "0  [0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "1  [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "3  [0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n",
      "4  [0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv(\"./ml-100k/u.item\",sep=\"|\",header=None,encoding = \"ISO-8859-1\")\n",
    "data=data.rename(columns={0:\"id\",1:\"title\",2:\"release\",3:\"vid_release\",4:\"URL\"})\n",
    "movies=pd.DataFrame(columns=[\"id\",\"title\",\"release\",\"genre\"])\n",
    "for row,i in data.iterrows():\n",
    "    movies.loc[row,:]=[i[\"id\"],i[\"title\"],i[\"release\"],[i[j] for j in range(5,24)]]\n",
    "print(movies.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe708836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   uid  mid  rating      epoch\n",
      "0    1    3       4  878542960\n",
      "1    1    4       3  876893119\n",
      "2    1    5       3  889751712\n",
      "3    1    6       5  887431973\n",
      "4    1    7       4  875071561\n"
     ]
    }
   ],
   "source": [
    "ratings=pd.read_csv(\"./ml-100k/u2.base\",sep=\"\\t\",header=None)\n",
    "ratings=ratings.rename(columns={0:\"uid\",1:\"mid\",2:\"rating\",3:\"epoch\"})\n",
    "print(ratings.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7de417c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 4. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [4. 3. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "rating_matrix=np.zeros(shape=(len(userProfiles),len(movies)))\n",
    "for idx,row in ratings.iterrows():\n",
    "    rating_matrix[row.uid-1][row.mid-1]=row.rating\n",
    "print(rating_matrix[:5][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42f355d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   uid  mid  rating      epoch\n",
      "0    1    1       5  874965758\n",
      "1    1    2       3  876893171\n",
      "2    1    8       1  875072484\n",
      "3    1    9       5  878543541\n",
      "4    1   21       1  878542772\n"
     ]
    }
   ],
   "source": [
    "test_ratings=pd.read_csv(\"./ml-100k/u2.test\",sep=\"\\t\",header=None)\n",
    "test_ratings=test_ratings.rename(columns={0:\"uid\",1:\"mid\",2:\"rating\",3:\"epoch\"})\n",
    "print(test_ratings.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4db198c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_movies = len(movies)\n",
    "num_users = len(userProfiles)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "394455a0",
   "metadata": {},
   "source": [
    "## Evaluation of the recommendations:\n",
    "Since all of the algorithms that I tried return a score on a scale of 0 to 5, evaluation of the algorithm is a straightforward task.\n",
    "Suppose $\\hat{y}_i, i \\in [1,n]$ denotes the predicted score returned for each item in the test data of length n, and ${y}_i, i \\in [1,n]$ denotes the actual score. To evaluate the performance of the recommendor system algorithm, I made use of the following two metrics.\n",
    "1. Mean Square Error (MSE): This is defined as follows:\n",
    "$$ MSE = \\frac{\\sum^{n}_{1}( \\hat{y}_i - y_i)^2}{n}$$\n",
    "2. Pearson Correlation \n",
    "\n",
    "While the algorithms do try to return a predicted score for each movie, I found that the algorithms were mostly predicting values close to 3.5, since the values were a result of averaging over multiple related scores. Also, the goal of the recommender system is to output the movies that the user is likely to enjoy the most, and not to actually predict the scores. Thus just testing for a correlation between the predicted values and the actual ratings should also be a good indicator of how good the recommendations are. Thus, our second evaluation metric is the Pearson correlation between $\\hat{y}_i$ and $y_i$. \n",
    "\n",
    "I found that both of these metrics were in tune with each other most of the times.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "502130de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_ratings(true_ratings,predicted_ratings):\n",
    "    mse = np.sum((true_ratings - predicted_ratings)**2)/len(test_ratings)\n",
    "    print(\"Mean Square Error: \" + str(mse))\n",
    "    pearson_corr = np.corrcoef(true_ratings,y = predicted_ratings)\n",
    "    print(\"Pearson Correlation: \" + str(pearson_corr[0][1]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9cf4f79a",
   "metadata": {},
   "source": [
    "## Approach 1: Matrix Factorisation\n",
    "In this approach, I factorise our ratings matrix into two matrices of smaller dimension, which shall represent the user feature matrix and the movie feature matrix. The idea behind this is that since the original matrix can be reconstructed by the dot product of the smaller matrices, I can use gradient descent on the individual matrices to get a fairy good approximation of the missing values in the original matrix.\n",
    "\n",
    "Note that the number of latent features to be considered, the learning rate (alpha) and the regularisation factor (beta) are hyperparameters in this approach.\n",
    "\n",
    "The loss function taken is the regularised square error -\n",
    "     $$ \\textrm{Error}= \\sum^{n}_{1} (\\textrm{actual rating} - \\textrm{predicted rating})^2+ L^2\\textrm{-Regularisation Term} $$\n",
    "\n",
    "This was taken according to the most recent approaches in the SVD algorithm \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb4779b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix Factorisation \n",
    "def fact(rating,userFeature,movieFeature,latent,steps,alpha,beta):\n",
    "    movieFeature=movieFeature.T\n",
    "    for s in range(steps):\n",
    "        for i in range(len(rating)):\n",
    "            for j in range(len(rating[i])):\n",
    "                if(rating[i][j]>0):\n",
    "                    err=rating[i][j]-np.dot(userFeature[i,:],movieFeature[:,j])\n",
    "                    for k in range(latent):\n",
    "                        # Calculating Gradient\n",
    "                        userFeature[i][k]=userFeature[i][k]+alpha*(2*err*movieFeature[k][j]-beta*userFeature[i][k])\n",
    "                        movieFeature[k][j]=movieFeature[k][j]+alpha*(2*err*userFeature[i][k]-beta*movieFeature[k][j])\n",
    "        #erating=np.dot(userFeature,movieFeature)\n",
    "        e=0\n",
    "        for i in range(len(rating)):\n",
    "            for j in range(len(rating[i])):\n",
    "                if(rating[i][j]>0):\n",
    "                    e=e+pow(rating[i][j]-np.dot(userFeature[i,:],movieFeature[:,j]),2)\n",
    "                    for k in range(latent):\n",
    "                        e=e+(beta/2)*(pow(userFeature[i][k],2)+pow(movieFeature[k][j],2))\n",
    "        if(e<0.1):\n",
    "            break\n",
    "    return userFeature,movieFeature.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54d2c334",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rating_matrix=np.array(rating_matrix)\n",
    "(n,m) = rating_matrix.shape\n",
    "latent=19\n",
    "userFeatures=np.random.rand(n,latent)\n",
    "movieFeatures=np.random.rand(m,latent)\n",
    "nU,nM=fact(rating_matrix,userFeatures,movieFeatures,latent,100,0.001,0.01)\n",
    "nR=np.dot(nU,nM.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5984f9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting Ratings\n",
    "def fact_predicted_score(u_id,m_id):\n",
    "    if(rating_matrix[u_id-1,m_id-1]!=0): # should not occur if train and test data are disjoint\n",
    "        print(\"Predicted: \",nR[u_id-1,m_id])\n",
    "        return \"Already seen, rated :\"+str(rating_matrix[u_id-1,m_id-1])\n",
    "    else:\n",
    "        return nR[u_id-1,m_id]\n",
    "    \n",
    "predicted_ratings = np.zeros(len(test_ratings))\n",
    "for i in range(len(test_ratings)):\n",
    "    predicted_ratings[i] = fact_predicted_score(test_ratings.loc[i,'uid'],test_ratings.loc[i,'mid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71639546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Square Error: 1.5194176531823604\n",
      "Pearson Correlation: 0.2787804333910821\n"
     ]
    }
   ],
   "source": [
    "evaluate_ratings(test_ratings['rating'],predicted_ratings)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "506f5612",
   "metadata": {},
   "source": [
    "## Approach 2: Item-based recommendations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4abd4838",
   "metadata": {},
   "source": [
    "In this approach, I made use of the similarity between movies to predict a user's rating for a movie that they have not seen. First, I computed the similarity between movies. I defined the similarity between movie $X$ and movie $Y$ as: \n",
    "\n",
    "$$sim(X,Y) = adjusted\\_cosine\\_similarity(user\\_ratings(X),user\\_ratings(Y)$$\n",
    "\n",
    "Thus I get a similarity matrix, where the $(i,j)^{th}$ element indicates the similarity between movie $i$ and movie $j$. Now, to get the predicted score for movie $M$ and user $U$, I used the function as defined in class:\n",
    "$$pred(U,M) = mean(ratings(U,:)) + \\frac{\\sum_{Z\\in N} sim(M,Z)*(rating(U,Z)-mean(ratings(U,:))}{\\sum_{Z\\in N}sim(M,Z)}$$\n",
    "Here, I tried defining N in two ways:\n",
    "1. Threshold based: $ N = \\{z: similarity(z,M)>\\lambda, z \\in \\hat{M}\\} $, where $\\lambda$ is a user defined threshold and $\\hat{M}$ is the set of all movies. \n",
    "2. Neighbors based: The set of n-most similar movies to movie $M$, where n is a user defined number \n",
    "\n",
    "Incase ${\\sum_{Z\\in N}sim(M,Z)} = 0,$ I just set $pred(U,M) = mean(ratings(U,:))$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "909d8249",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computes similarity between movie X and Y using adjusted cosine similarity\n",
    "def item_cosine_similarity(X,Y):\n",
    "    X_mean = np.mean(X)\n",
    "    Y_mean = np.mean(Y)\n",
    "    if(X_mean==0 or Y_mean==0):\n",
    "        return [[0]]\n",
    "    X_adj = X-X_mean\n",
    "    Y_adj = Y-Y_mean\n",
    "    similarity = pairwise.cosine_similarity(X_adj.reshape(1,-1),Y_adj.reshape(1,-1))\n",
    "    return similarity\n",
    "#Returns the predicted score for movie i for a user j\n",
    "def item_based_predicted_score(user_id,movie_id,similarity_matrix,rating_matrix,n_neighbors = 10,type = 'threshold'):\n",
    "    score=0\n",
    "    count=0\n",
    "    sim_sum = 0\n",
    "    l=[]\n",
    "    if(rating_matrix[user_id-1,movie_id-1]!=0):\n",
    "        ## Movie is already watched\n",
    "        return -1\n",
    "    else:\n",
    "        if(type=='neighbors'):\n",
    "            top_neighbors = np.flip(np.argsort(similarity_matrix[:,movie_id-1]))\n",
    "            for i in top_neighbors:\n",
    "                if(rating_matrix[user_id-1,i]!=0):\n",
    "                    mean = np.mean(rating_matrix[:,i])\n",
    "                    l.append(i)\n",
    "                    score+=similarity_matrix[movie_id-1][i]*(rating_matrix[user_id-1,i] - mean)\n",
    "                    sim_sum+=similarity_matrix[movie_id-1][i]\n",
    "                    count+=1\n",
    "                    if(count==n_neighbors):\n",
    "                        break\n",
    "        if(type == 'threshold'):\n",
    "            for i in range(len(rating_matrix[user_id-1])):\n",
    "                if(rating_matrix[user_id-1,i]!=0 and similarity_matrix[movie_id-1][i]>0):\n",
    "                    mean = np.mean(rating_matrix[:,i])\n",
    "                    l.append(i)\n",
    "                    score+=similarity_matrix[movie_id-1][i]*(rating_matrix[user_id-1,i] - mean)\n",
    "                    sim_sum+=similarity_matrix[movie_id-1][i]\n",
    "                    count+=1\n",
    "        if(count==0):\n",
    "            return 0\n",
    "        if(sim_sum==0):\n",
    "            predicted_rating = np.mean(rating_matrix[:,i])\n",
    "        else:\n",
    "            predicted_rating = np.mean(rating_matrix[:,i]) + score/sim_sum\n",
    "        return predicted_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1919f497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.33518385 0.2457249  ... 0.         0.05290709 0.05290709]\n",
      " [0.33518385 1.         0.20116515 ... 0.         0.08522865 0.08522865]\n",
      " [0.2457249  0.20116515 1.         ... 0.         0.         0.11420805]\n",
      " ...\n",
      " [0.         0.         0.         ... 1.         0.         0.        ]\n",
      " [0.05290709 0.08522865 0.         ... 0.         1.         0.        ]\n",
      " [0.05290709 0.08522865 0.11420805 ... 0.         0.         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "similarity_matrix_item=cosine_similarity(rating_matrix.T)\n",
    "print(similarity_matrix_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5650e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          0.18559869  0.12886179 ... -0.02440874  0.04173334\n",
      "   0.04173334]\n",
      " [ 0.18559869  1.          0.13326154 ... -0.01118631  0.07897345\n",
      "   0.07897345]\n",
      " [ 0.12886179  0.13326154  1.         ... -0.0081614  -0.0081614\n",
      "   0.10963762]\n",
      " ...\n",
      " [-0.02440874 -0.01118631 -0.0081614  ...  1.         -0.00106157\n",
      "  -0.00106157]\n",
      " [ 0.04173334  0.07897345 -0.0081614  ... -0.00106157  1.\n",
      "  -0.00106157]\n",
      " [ 0.04173334  0.07897345  0.10963762 ... -0.00106157 -0.00106157\n",
      "   1.        ]]\n"
     ]
    }
   ],
   "source": [
    "#Computes the similarity matrix\n",
    "similarity_matrix_item=cosine_similarity(rating_matrix.T)\n",
    "print(similarity_matrix_item)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ab775556",
   "metadata": {},
   "source": [
    "On the validation set u1, I found that the neighbors method works better with $n = 8$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22447127",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_ratings = np.zeros(len(test_ratings))\n",
    "for i in range(len(test_ratings)):\n",
    "    predicted_ratings[i] =  item_based_predicted_score(test_ratings.loc[i,'uid'],test_ratings.loc[i,'mid'],similarity_matrix_item,rating_matrix,n_neighbors = 8,type = 'neighbors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "225c9edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    # Ensure that y_true and y_pred are NumPy arrays\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    \n",
    "    # Calculate the squared differences\n",
    "    squared_diff = (y_true - y_pred) ** 2\n",
    "    \n",
    "    # Calculate the mean of the squared differences\n",
    "    mean_squared_diff = np.mean(squared_diff)\n",
    "    \n",
    "    # Calculate the square root to get RMSE\n",
    "    rmse_value = np.sqrt(mean_squared_diff)\n",
    "    \n",
    "    return rmse_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc2d15cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0468753129757744"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse(test_ratings['rating'],predicted_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "991b56e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Square Error: 1.0280864092559379\n",
      "Pearson Correlation: 0.48620088979496545\n"
     ]
    }
   ],
   "source": [
    "evaluate_ratings(test_ratings['rating'],predicted_ratings)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7889cb40",
   "metadata": {},
   "source": [
    "I also have some more information available about the movies, which is the genres that they belong to. This can be useful information in computing the similarity between movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "28aaf3a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>title</th>\n",
       "      <th>release_date</th>\n",
       "      <th>video_release_date</th>\n",
       "      <th>IMDb_URL</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Children's</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>...</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Toy%20Story%2...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?GoldenEye%20(...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Four Rooms (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Four%20Rooms%...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Get Shorty (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Get%20Shorty%...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Copycat (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Copycat%20(1995)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id              title release_date  video_release_date  \\\n",
       "0         1   Toy Story (1995)  01-Jan-1995                 NaN   \n",
       "1         2   GoldenEye (1995)  01-Jan-1995                 NaN   \n",
       "2         3  Four Rooms (1995)  01-Jan-1995                 NaN   \n",
       "3         4  Get Shorty (1995)  01-Jan-1995                 NaN   \n",
       "4         5     Copycat (1995)  01-Jan-1995                 NaN   \n",
       "\n",
       "                                            IMDb_URL  Action  Adventure  \\\n",
       "0  http://us.imdb.com/M/title-exact?Toy%20Story%2...       0          0   \n",
       "1  http://us.imdb.com/M/title-exact?GoldenEye%20(...       1          1   \n",
       "2  http://us.imdb.com/M/title-exact?Four%20Rooms%...       0          0   \n",
       "3  http://us.imdb.com/M/title-exact?Get%20Shorty%...       1          0   \n",
       "4  http://us.imdb.com/M/title-exact?Copycat%20(1995)       0          0   \n",
       "\n",
       "   Animation  Children's  Comedy  ...  Fantasy  Film-Noir  Horror  Musical  \\\n",
       "0          1           1       1  ...        0          0       0        0   \n",
       "1          0           0       0  ...        0          0       0        0   \n",
       "2          0           0       0  ...        0          0       0        0   \n",
       "3          0           0       1  ...        0          0       0        0   \n",
       "4          0           0       0  ...        0          0       0        0   \n",
       "\n",
       "   Mystery  Romance  Sci-Fi  Thriller  War  Western  \n",
       "0        0        0       0         0    0        0  \n",
       "1        0        0       0         1    0        0  \n",
       "2        0        0       0         1    0        0  \n",
       "3        0        0       0         0    0        0  \n",
       "4        0        0       0         1    0        0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_columns = [\"movie_id\", \"title\", \"release_date\", \"video_release_date\", \"IMDb_URL\"]\n",
    "genre_columns = [\n",
    "    \"unknown\", \"Action\", \"Adventure\", \"Animation\", \"Children's\", \"Comedy\", \"Crime\", \"Documentary\",\n",
    "    \"Drama\", \"Fantasy\", \"Film-Noir\", \"Horror\", \"Musical\", \"Mystery\", \"Romance\", \"Sci-Fi\", \"Thriller\",\n",
    "    \"War\", \"Western\"\n",
    "]\n",
    "data = pd.read_csv(\"./ml-100k/u.item\", sep=\"|\", header=None, encoding=\"ISO-8859-1\")\n",
    "data.columns = [\"movie_id\"] + movie_columns[1:] + genre_columns\n",
    "data.drop(columns = 'unknown',inplace = True)\n",
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e72427f5",
   "metadata": {},
   "source": [
    "I first compute the tf-idf scores, and then calculate the adjusted cosine similarity between the movies only based on the genre information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c4636bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adventure</th>\n",
       "      <th>animation</th>\n",
       "      <th>children</th>\n",
       "      <th>comedy</th>\n",
       "      <th>crime</th>\n",
       "      <th>documentary</th>\n",
       "      <th>drama</th>\n",
       "      <th>fantasy</th>\n",
       "      <th>fi</th>\n",
       "      <th>film</th>\n",
       "      <th>horror</th>\n",
       "      <th>musical</th>\n",
       "      <th>mystery</th>\n",
       "      <th>noir</th>\n",
       "      <th>romance</th>\n",
       "      <th>sci</th>\n",
       "      <th>thriller</th>\n",
       "      <th>war</th>\n",
       "      <th>western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.74066</td>\n",
       "      <td>0.573872</td>\n",
       "      <td>0.349419</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.771538</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.636183</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.767200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.641408</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.735504</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.363186</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.571953</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   adventure  animation  children    comedy     crime  documentary     drama  \\\n",
       "0   0.000000    0.74066  0.573872  0.349419  0.000000          0.0  0.000000   \n",
       "1   0.771538    0.00000  0.000000  0.000000  0.000000          0.0  0.000000   \n",
       "2   0.000000    0.00000  0.000000  0.000000  0.000000          0.0  0.000000   \n",
       "3   0.000000    0.00000  0.000000  0.767200  0.000000          0.0  0.641408   \n",
       "4   0.000000    0.00000  0.000000  0.000000  0.735504          0.0  0.363186   \n",
       "\n",
       "   fantasy   fi  film  horror  musical  mystery  noir  romance  sci  thriller  \\\n",
       "0      0.0  0.0   0.0     0.0      0.0      0.0   0.0      0.0  0.0  0.000000   \n",
       "1      0.0  0.0   0.0     0.0      0.0      0.0   0.0      0.0  0.0  0.636183   \n",
       "2      0.0  0.0   0.0     0.0      0.0      0.0   0.0      0.0  0.0  1.000000   \n",
       "3      0.0  0.0   0.0     0.0      0.0      0.0   0.0      0.0  0.0  0.000000   \n",
       "4      0.0  0.0   0.0     0.0      0.0      0.0   0.0      0.0  0.0  0.571953   \n",
       "\n",
       "   war  western  \n",
       "0  0.0      0.0  \n",
       "1  0.0      0.0  \n",
       "2  0.0      0.0  \n",
       "3  0.0      0.0  \n",
       "4  0.0      0.0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['genres_list'] = data.apply(lambda row: ','.join(row[6:].index[row[6:] == 1]),axis=1)\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(data['genres_list'])\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(),columns=tfidf_vectorizer.get_feature_names_out())\n",
    "tfidf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "829fe764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.         -0.1409362  -0.09734822 ... -0.13778894  0.29105884\n",
      "  -0.09734822]\n",
      " [-0.1409362   1.          0.61019237 ... -0.11384354 -0.08043074\n",
      "  -0.08043074]\n",
      " [-0.09734822  0.61019237  1.         ... -0.07863463 -0.05555556\n",
      "  -0.05555556]\n",
      " ...\n",
      " [-0.13778894 -0.11384354 -0.07863463 ...  1.         -0.07863463\n",
      "   0.49967011]\n",
      " [ 0.29105884 -0.08043074 -0.05555556 ... -0.07863463  1.\n",
      "  -0.05555556]\n",
      " [-0.09734822 -0.08043074 -0.05555556 ...  0.49967011 -0.05555556\n",
      "   1.        ]]\n"
     ]
    }
   ],
   "source": [
    "similarity_matrix_item_genre=np.zeros(shape=(num_movies,num_movies))\n",
    "for i in range(num_movies):\n",
    "    for j in range(num_movies):\n",
    "        similarity_matrix_item_genre[i,j]=item_cosine_similarity(np.array(tfidf_df)[i,:],np.array(tfidf_df)[j,:])[0][0]\n",
    "print(similarity_matrix_item_genre)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8169138b",
   "metadata": {},
   "source": [
    "To get the final predictions, I use a weighted sum of the predictions obtained based on user and movie ratings, and the predictions obtained based on genre information. I found that a weight of 0.8 for ratings based predictions gave the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c01ab049",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = 0.8\n",
    "predicted_ratings = np.zeros(len(test_ratings))\n",
    "for i in range(len(test_ratings)):\n",
    "    predicted_ratings[i] =  weight*item_based_predicted_score(test_ratings.loc[i,'uid'],test_ratings.loc[i,'mid'],similarity_matrix_item ,rating_matrix,n_neighbors = 8,type = 'neighbors') + (1-weight)*item_based_predicted_score(test_ratings.loc[i,'uid'],test_ratings.loc[i,'mid'],similarity_matrix_item_genre ,rating_matrix,type = 'threshold')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5c7a616c",
   "metadata": {},
   "source": [
    "There is only a slight increase in accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "afa091aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Square Error: 0.9757337468455628\n",
      "Pearson Correlation: 0.4985341576258008\n"
     ]
    }
   ],
   "source": [
    "evaluate_ratings(test_ratings['rating'],predicted_ratings)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2e22774b",
   "metadata": {},
   "source": [
    "## Approach 3: Profile Based recommendations\n",
    "In this approach, I made use of the similarity between users to predict a user's rating for a movie that they have not seen. First, I computed the similarity between users. I defined the similarity between user $X$ and user $Y$ as: \n",
    "\n",
    "$$sim(X,Y) = adjusted\\_pearson\\_correlation(movie\\_ratings(X),movie\\_ratings(Y)$$\n",
    "\n",
    "Thus I get a similarity matrix, where the $(i,j)^{th}$ element indicates the similarity between user $i$ and user $j$. Now, to get the predicted score for movie $M$ and user $U$, I used the function as defined in class:\n",
    "$$pred(U,M) = mean(ratings(:,M)) + \\frac{\\sum_{Z\\in N} sim(U,Z)*(rating(Z,M)-mean(ratings(:,M))}{\\sum_{Z\\in N}sim(U,Z)}$$\n",
    "Here, I tried defining N in two ways:\n",
    "1. Threshold based: $ N = \\{z: similarity(U,z)>\\lambda, z \\in \\hat{U}\\} $, where $\\lambda$ is a user defined threshold and $\\hat{U}$ is the set of all users. \n",
    "2. Neighbors based: The set of n-most similar users to user $U$, where n is a user defined number \n",
    "\n",
    "Incase ${\\sum_{Z\\in N}sim(U,Z)} = 0,$ I just set $pred(U,M) = mean(ratings(:,M))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bba8cec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Computes adjusted pearson correlation between X and Y\n",
    "def user_pearson_similarity(X,Y):\n",
    "    X_mean = np.mean(X)\n",
    "    Y_mean = np.mean(Y)\n",
    "    if(X_mean==0 or Y_mean==0):\n",
    "        return [[0],[0]]\n",
    "    X_adj = X-X_mean\n",
    "    Y_adj = Y-Y_mean\n",
    "    similarity = np.corrcoef(X_adj,Y_adj)\n",
    "    return similarity\n",
    "## Computes the predicted score for given user U and movie M\n",
    "def user_based_predicted_score(user_id,movie_id,similarity_matrix,rating_matrix,n_neighbors = 10,type = 'threshold',threshold = 0):\n",
    "    score=0\n",
    "    count=0\n",
    "    sim_sum = 0\n",
    "    l=[]\n",
    "    if(rating_matrix[user_id-1,movie_id-1]!=0):\n",
    "        return -1\n",
    "    else:\n",
    "        if(type=='neighbors'):\n",
    "            top_neighbors = np.flip(np.argsort(similarity_matrix[user_id-1,:]))\n",
    "            for i in top_neighbors:\n",
    "                if(rating_matrix[i,movie_id-1]!=0):\n",
    "                    mean = np.mean(rating_matrix[i,:])\n",
    "                    l.append(i)\n",
    "                    score+=similarity_matrix[user_id-1][i]*(rating_matrix[i,movie_id-1] - mean)\n",
    "                    sim_sum+=similarity_matrix[user_id-1][i]\n",
    "                    count+=1\n",
    "                    if(count==n_neighbors):\n",
    "                        break\n",
    "        if(type == 'threshold'):\n",
    "            for i in range(len(rating_matrix[:,movie_id-1])):\n",
    "                if(rating_matrix[i,movie_id-1]!=0 and similarity_matrix[user_id-1][i]>threshold):\n",
    "                    mean = np.mean(rating_matrix[i,:])\n",
    "                    l.append(i)\n",
    "                    score+=similarity_matrix[user_id-1][i]*(rating_matrix[i,movie_id-1] - mean)\n",
    "                    sim_sum+=similarity_matrix[user_id-1][i]\n",
    "                    count+=1\n",
    "        if(count==0):\n",
    "            return 0\n",
    "        if(sim_sum==0):\n",
    "            predicted_rating = np.mean(rating_matrix[:,i])\n",
    "        else:\n",
    "            predicted_rating = np.mean(rating_matrix[:,i]) + score/sim_sum\n",
    "        return predicted_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e18714d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          0.05985147 -0.03696226 ...  0.06026923  0.09672882\n",
      "   0.29232671]\n",
      " [ 0.05985147  1.          0.06717595 ...  0.08067685  0.13000657\n",
      "   0.05524174]\n",
      " [-0.03696226  0.06717595  1.         ...  0.03121862  0.09862254\n",
      "  -0.02759119]\n",
      " ...\n",
      " [ 0.06026923  0.08067685  0.03121862 ...  1.          0.08012962\n",
      "   0.06529963]\n",
      " [ 0.09672882  0.13000657  0.09862254 ...  0.08012962  1.\n",
      "   0.12773543]\n",
      " [ 0.29232671  0.05524174 -0.02759119 ...  0.06529963  0.12773543\n",
      "   1.        ]]\n"
     ]
    }
   ],
   "source": [
    "similarity_matrix_user=np.zeros(shape=(num_users,num_users))\n",
    "for i in range(num_users):\n",
    "    for j in range(num_users):\n",
    "        similarity_matrix_user[i,j]=user_pearson_similarity(rating_matrix[i,:],rating_matrix[j,:])[0][1]\n",
    "print(similarity_matrix_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4cecf8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_ratings = np.zeros(len(test_ratings))\n",
    "for i in range(len(test_ratings)):\n",
    "    predicted_ratings[i] =  user_based_predicted_score(test_ratings.loc[i,'uid'],test_ratings.loc[i,'mid'],similarity_matrix_user,rating_matrix,type = 'threshold',threshold = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "92c909cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Square Error: 1.117923616944161\n",
      "Pearson Correlation: 0.42758331685477824\n"
     ]
    }
   ],
   "source": [
    "evaluate_ratings(test_ratings['rating'],predicted_ratings)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "60cc9400",
   "metadata": {},
   "source": [
    "I also have some more information available regarding the users, which is the demographic information. The demographic information can play a crucial role in computing the similarity between users. \n",
    "\n",
    "The user profile data had the zip code for each user. Geographical location greatly impacts culture, which in turn impacts what kind of movies people enjoy. Thus this information is important, and can be extracted from the zip code. I used the library geopy to do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "98b4f726",
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocator = Nominatim(user_agent=\"geoapiExercises\")\n",
    "userProfiles['country'] = \"NA\"\n",
    "userProfiles['state'] = \"NA\"\n",
    "for i in range(len(userProfiles)):\n",
    "    try:\n",
    "        location = geolocator.geocode(userProfiles.loc[i,'zip'])\n",
    "        userProfiles.loc[i,'country'] = location[0].split(\", \")[-1]\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1ddd853b",
   "metadata": {},
   "source": [
    "I filtered out countries that had less than 5 users belonging to them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e2f495a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "less_info = userProfiles['country'].value_counts()[(userProfiles['country'].value_counts() < 5)].index\n",
    "userProfiles.loc[np.isin(userProfiles['country'],np.array(less_info)),'country'] = \"NA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "42e7340c",
   "metadata": {},
   "outputs": [],
   "source": [
    "userProfiles['country'] = userProfiles['country'].str.replace(' ', '_')\n",
    "userProfiles['country'] = userProfiles['country'].str.replace('/', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8fe799ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "userProfiles_dummy = pd.get_dummies(userProfiles,columns = ['country','occupation','sex'])\n",
    "userProfiles_dummy.drop(columns = ['country_NA','occupation_other'],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0613c811",
   "metadata": {},
   "outputs": [],
   "source": [
    "userProfiles_dummy.drop(columns = ['state','zip','age','id'],inplace = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "56b75cdd",
   "metadata": {},
   "source": [
    "I obtained the tf-idf representation for the demographics, including the country information and the sex information, and then obtained the similarity matrix using adjusted pearson correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b7fe7190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_hrvatska</th>\n",
       "      <th>country_indonesia</th>\n",
       "      <th>country_italia</th>\n",
       "      <th>country_lietuva</th>\n",
       "      <th>country_maroc_ⵍⵎⵖⵔⵉⴱ_المغرب</th>\n",
       "      <th>country_méxico</th>\n",
       "      <th>country_polska</th>\n",
       "      <th>country_slovensko</th>\n",
       "      <th>country_suomi___finland</th>\n",
       "      <th>country_sverige</th>\n",
       "      <th>...</th>\n",
       "      <th>occupation_none</th>\n",
       "      <th>occupation_programmer</th>\n",
       "      <th>occupation_retired</th>\n",
       "      <th>occupation_salesman</th>\n",
       "      <th>occupation_scientist</th>\n",
       "      <th>occupation_student</th>\n",
       "      <th>occupation_technician</th>\n",
       "      <th>occupation_writer</th>\n",
       "      <th>sex_f</th>\n",
       "      <th>sex_m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.880031</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.261278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.379583</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.582284</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.194219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.880031</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.261278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.490070</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   country_hrvatska  country_indonesia  country_italia  country_lietuva  \\\n",
       "0               0.0                0.0             0.0              0.0   \n",
       "1               0.0                0.0             0.0              0.0   \n",
       "2               0.0                0.0             0.0              0.0   \n",
       "3               0.0                0.0             0.0              0.0   \n",
       "4               0.0                0.0             0.0              0.0   \n",
       "\n",
       "   country_maroc_ⵍⵎⵖⵔⵉⴱ_المغرب  country_méxico  country_polska  \\\n",
       "0                          0.0             0.0             0.0   \n",
       "1                          0.0             0.0             0.0   \n",
       "2                          0.0             0.0             0.0   \n",
       "3                          0.0             0.0             0.0   \n",
       "4                          0.0             0.0             0.0   \n",
       "\n",
       "   country_slovensko  country_suomi___finland  country_sverige  ...  \\\n",
       "0                0.0                      0.0              0.0  ...   \n",
       "1                0.0                      0.0              0.0  ...   \n",
       "2                0.0                      0.0              0.0  ...   \n",
       "3                0.0                      0.0              0.0  ...   \n",
       "4                0.0                      0.0              0.0  ...   \n",
       "\n",
       "   occupation_none  occupation_programmer  occupation_retired  \\\n",
       "0              0.0                    0.0                 0.0   \n",
       "1              0.0                    0.0                 0.0   \n",
       "2              0.0                    0.0                 0.0   \n",
       "3              0.0                    0.0                 0.0   \n",
       "4              0.0                    0.0                 0.0   \n",
       "\n",
       "   occupation_salesman  occupation_scientist  occupation_student  \\\n",
       "0                  0.0                   0.0                 0.0   \n",
       "1                  0.0                   0.0                 0.0   \n",
       "2                  0.0                   0.0                 0.0   \n",
       "3                  0.0                   0.0                 0.0   \n",
       "4                  0.0                   0.0                 0.0   \n",
       "\n",
       "   occupation_technician  occupation_writer     sex_f     sex_m  \n",
       "0               0.880031           0.000000  0.000000  0.261278  \n",
       "1               0.000000           0.000000  0.379583  0.000000  \n",
       "2               0.000000           0.582284  0.000000  0.194219  \n",
       "3               0.880031           0.000000  0.000000  0.261278  \n",
       "4               0.000000           0.000000  0.490070  0.000000  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userProfiles_dummy['demographics_list'] = userProfiles_dummy.apply(lambda row: ','.join(row[6:].index[row[6:] == 1]), axis=1)\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(userProfiles_dummy['demographics_list'])\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "tfidf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "764e13cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.         -0.05428283 -0.01172943 ...  0.07164157 -0.07076029\n",
      "   0.2794357 ]\n",
      " [-0.05428283  1.          0.71615281 ... -0.04728051  0.08404554\n",
      "  -0.05963554]\n",
      " [-0.01172943  0.71615281  1.         ...  0.03784126 -0.0721369\n",
      "   0.00661615]\n",
      " ...\n",
      " [ 0.07164157 -0.04728051  0.03784126 ...  1.         -0.06163243\n",
      "   0.80813699]\n",
      " [-0.07076029  0.08404554 -0.0721369  ... -0.06163243  1.\n",
      "  -0.07773779]\n",
      " [ 0.2794357  -0.05963554  0.00661615 ...  0.80813699 -0.07773779\n",
      "   1.        ]]\n"
     ]
    }
   ],
   "source": [
    "similarity_matrix_user_demo=np.zeros(shape=(num_users,num_users))\n",
    "for i in range(num_users):\n",
    "    for j in range(num_users):\n",
    "        similarity_matrix_user_demo[i,j]=user_pearson_similarity(np.array(tfidf_df)[i,:],np.array(tfidf_df)[j,:])[0][1]\n",
    "print(similarity_matrix_user_demo)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5d705681",
   "metadata": {},
   "source": [
    "I then took a weighted sum of the predictions obtained using the ratings information and the predictions obtained using the demographics information. I found that a weight of 0.9 on the predictions obtained using the ratings gave the best results, although the increase in accuracy is small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eefe942b",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = 0.9\n",
    "predicted_ratings = np.zeros(len(test_ratings))\n",
    "for i in range(len(test_ratings)):\n",
    "    predicted_ratings[i] =  weight*user_based_predicted_score(test_ratings.loc[i,'uid'],test_ratings.loc[i,'mid'],similarity_matrix_user,rating_matrix,type = 'threshold') + (1-weight)*user_based_predicted_score(test_ratings.loc[i,'uid'],test_ratings.loc[i,'mid'],similarity_matrix_user_demo ,rating_matrix,type = 'threshold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4aacbdfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Square Error: 1.115142160603081\n",
      "Pearson Correlation: 0.4287607951752191\n"
     ]
    }
   ],
   "source": [
    "evaluate_ratings(test_ratings['rating'],predicted_ratings)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f80f56c3",
   "metadata": {},
   "source": [
    "## Approach 4: Hybrid: Combining predictions from user-based and profile-based approaches\n",
    "To combine the predictions, I simply took a weighted sum of the predictions from the profile-based algorithm and the content-based algorithm. I found that a weight of 0.5 on the user-based algorithm gives the best results. \n",
    "In a way, the weight on the user based predictions can be adjusted to account for Serendipity. The higher this weight is, the better will be the Serendipity of the algorithm, since more weightage will be given to the user based approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "338afffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_weight = 0.5\n",
    "predicted_ratings = np.zeros(len(test_ratings))\n",
    "for i in range(len(test_ratings)):\n",
    "    predicted_ratings[i] =  user_weight*user_based_predicted_score(test_ratings.loc[i,'uid'],test_ratings.loc[i,'mid'],similarity_matrix_user,rating_matrix,type = 'threshold',threshold = 0) + (1-user_weight)*item_based_predicted_score(test_ratings.loc[i,'uid'],test_ratings.loc[i,'mid'],similarity_matrix_item,rating_matrix,n_neighbors = 8,type = 'neighbors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "94dcf5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Square Error: 0.894633334321835\n",
      "Pearson Correlation: 0.5575564146121965\n"
     ]
    }
   ],
   "source": [
    "evaluate_ratings(test_ratings['rating'],predicted_ratings)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3636581f",
   "metadata": {},
   "source": [
    "## Summary of methods\n",
    "<div align=\"center\">\n",
    "    \n",
    "| Method    | RMSE | Correlation |\n",
    "| :-----------: | :-----------: | :-----------: |\n",
    "| Matrix Factorisation Based      | 1.529       | 0.280 |\n",
    "| Item based (ratings)  | 1.028        | 0.486 |\n",
    "| Item-based with genre information  | 0.976      | 0.498 |\n",
    "| Profile Based CF (ratings)  | 1.118       | 0.427 |\n",
    "| Profile Based CF with demographics information   | 1.115        | 0. 429|\n",
    "| Hybrid   | 0.895       | 0.558 |\n",
    "    \n",
    "</div>\n",
    "\n",
    "As expected, the more information that I feed the system, the better results I get, and therefore the hybrid algor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "64783c17",
   "metadata": {},
   "source": [
    "## Final Recommender System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "688cadfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d57a2d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 0.5\n",
    "data['predicted_ratings'] = -1\n",
    "for i in range(len(data)):\n",
    "    data.loc[i,'predicted_ratings'] =  s*(0.9*user_based_predicted_score(user_id,i+1,similarity_matrix_user,rating_matrix,type = 'threshold') + 0.1*user_based_predicted_score(user_id,i+1,similarity_matrix_user_demo ,rating_matrix,type = 'threshold'))+(1-s)*(0.8*item_based_predicted_score(user_id,i+1,similarity_matrix_item ,rating_matrix,n_neighbors = 8,type = 'neighbors') + 0.2*item_based_predicted_score(user_id,i+1,similarity_matrix_item_genre ,rating_matrix,type = 'threshold'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d5ca9c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Movies:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                                     Boot, Das (1981)\n",
       "1                       They Made Me a Criminal (1939)\n",
       "2                                 Aiqing wansui (1994)\n",
       "3                                         Faust (1994)\n",
       "4               World of Apu, The (Apur Sansar) (1959)\n",
       "5                                   Little City (1998)\n",
       "6    Wonderful, Horrible Life of Leni Riefenstahl, ...\n",
       "7                                 Kaspar Hauser (1993)\n",
       "8                               Golden Earrings (1947)\n",
       "9           Marlene Dietrich: Shadow and Light (1996) \n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Recommended Movies:\")\n",
    "data.sort_values('predicted_ratings',ascending = False)['title'][0:10].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6ebcc3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "genres_wanted = [\"Comedy\",\"Horror\"]\n",
    "genres_not_wanted = [\"Musical\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "74c842d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub1 = (data.loc[:,genres_wanted] == 1).all(axis=1)\n",
    "sub2 = (data.loc[:,genres_not_wanted] == 0).all(axis=1)\n",
    "sub3 = (data.loc[:, 'predicted_ratings'] != -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "de85536e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Movies, in the specific genres:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                              Bad Taste (1987)\n",
       "1            Dracula: Dead and Loving It (1995)\n",
       "2    Cemetery Man (Dellamorte Dellamore) (1994)\n",
       "3                              Braindead (1992)\n",
       "4                             Serial Mom (1994)\n",
       "5                           Howling, The (1981)\n",
       "6                    Tales from the Hood (1995)\n",
       "7                       April Fool's Day (1986)\n",
       "8                           Machine, The (1994)\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Recommended Movies, in the specific genres:\")\n",
    "data[sub1*sub2*sub3].sort_values('predicted_ratings',ascending = False)['title'][0:10].reset_index(drop = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
